{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Input\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.models import Model, Sequential \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow\n",
    "tensorflow.random.set_seed(2020)\n",
    "np.random.seed(2020)\n",
    "random.seed(2020)\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 150)\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_feature(data, outliersdata, dataname):\n",
    "    redundant_col = ['Unnamed: 0','入口网络编号', '出口网络编号', '出口车道编号','车种代码','免费类型代码',\n",
    "                     '支付方式代码','cluster','车牌号','路径标识', 'ETC车辆电子标签OBU编号']\n",
    "    \n",
    "    data = data.drop(redundant_col, axis=1)\n",
    "    outliersdata = outliersdata.drop(redundant_col, axis=1)\n",
    "    data['入口站编号'] = data['入口站编号'].astype('str')\n",
    "    data['出口站编号'] = data['出口站编号'].astype('str')\n",
    "    data['轴型及轴重'] = data['轴型及轴重'].astype('str')\n",
    "\n",
    "    outliersdata['入口站编号'] = outliersdata['入口站编号'].astype('str')\n",
    "    outliersdata['出口站编号'] = outliersdata['出口站编号'].astype('str')\n",
    "    outliersdata['轴型及轴重'] = outliersdata['轴型及轴重'].astype('str')\n",
    "\n",
    "\n",
    "    leEntryCode = preprocessing.LabelEncoder()\n",
    "    data['入口站编号'] = leEntryCode.fit_transform(data['入口站编号'])\n",
    "    outliersdata['入口站编号'] = leEntryCode.fit_transform(outliersdata['入口站编号'])\n",
    "\n",
    "    leExitCode = preprocessing.LabelEncoder()\n",
    "    data['出口站编号'] = leExitCode.fit_transform(data['出口站编号'])\n",
    "    outliersdata['出口站编号'] = leExitCode.fit_transform(outliersdata['出口站编号'])\n",
    "\n",
    "    leVCode = preprocessing.LabelEncoder()\n",
    "    data['轴型及轴重'] = leVCode.fit_transform(data['轴型及轴重'])\n",
    "    outliersdata['轴型及轴重'] = leVCode.fit_transform(outliersdata['轴型及轴重'])\n",
    "    \n",
    "    data['入口日期及时间'] = pd.to_datetime(data['入口日期及时间'])\n",
    "    outliersdata['入口日期及时间'] = pd.to_datetime(outliersdata['入口日期及时间'])\n",
    "\n",
    "    data['出口日期及时间'] = pd.to_datetime(data['出口日期及时间'])\n",
    "    outliersdata['出口日期及时间'] = pd.to_datetime(outliersdata['出口日期及时间'])\n",
    "\n",
    "    data['entryweek'] = data['入口日期及时间'].dt.week\n",
    "    data['entryday'] = data['入口日期及时间'].dt.day\n",
    "    data['entryhour'] = data['入口日期及时间'].dt.hour\n",
    "\n",
    "    outliersdata['entryweek'] = outliersdata['入口日期及时间'].dt.week\n",
    "    outliersdata['entryday'] = outliersdata['入口日期及时间'].dt.day\n",
    "    outliersdata['entryhour'] = outliersdata['入口日期及时间'].dt.hour\n",
    "\n",
    "    data['exitweek'] = data['出口日期及时间'].dt.week\n",
    "    data['exitday'] = data['出口日期及时间'].dt.day\n",
    "    data['exithour'] = data['出口日期及时间'].dt.hour\n",
    "\n",
    "    outliersdata['exitweek'] = outliersdata['出口日期及时间'].dt.week\n",
    "    outliersdata['exitday'] = outliersdata['出口日期及时间'].dt.day\n",
    "    outliersdata['exithour'] = outliersdata['出口日期及时间'].dt.hour\n",
    "    \n",
    "    df_group = data.groupby('车型代码')['超限率']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['车型代码超限率均值'] = data['车型代码'].map(building_mean)\n",
    "    data['车型代码超限率中位数'] = data['车型代码'].map(building_median)\n",
    "    data['车型代码超限率最小值'] = data['车型代码'].map(building_min)\n",
    "    data['车型代码超限率最大值'] = data['车型代码'].map(building_max)\n",
    "    data['车型代码超限率标准差'] = data['车型代码'].map(building_std)\n",
    "\n",
    "    outliersdata['车型代码超限率均值'] = outliersdata['车型代码'].map(building_mean)\n",
    "    outliersdata['车型代码超限率中位数'] = outliersdata['车型代码'].map(building_median)\n",
    "    outliersdata['车型代码超限率最小值'] = outliersdata['车型代码'].map(building_min)\n",
    "    outliersdata['车型代码超限率最大值'] = outliersdata['车型代码'].map(building_max)\n",
    "    outliersdata['车型代码超限率标准差'] = outliersdata['车型代码'].map(building_std)\n",
    "    \n",
    "    df_group = data.groupby('车型代码')['行驶时间']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['车型代码行驶时间均值'] = data['车型代码'].map(building_mean)\n",
    "    data['车型代码行驶时间中位数'] = data['车型代码'].map(building_median)\n",
    "    data['车型代码行驶时间最小值'] = data['车型代码'].map(building_min)\n",
    "    data['车型代码行驶时间最大值'] = data['车型代码'].map(building_max)\n",
    "    data['车型代码行驶时间标准差'] = data['车型代码'].map(building_std)\n",
    "\n",
    "    outliersdata['车型代码行驶时间均值'] = outliersdata['车型代码'].map(building_mean)\n",
    "    outliersdata['车型代码行驶时间中位数'] = outliersdata['车型代码'].map(building_median)\n",
    "    outliersdata['车型代码行驶时间最小值'] = outliersdata['车型代码'].map(building_min)\n",
    "    outliersdata['车型代码行驶时间最大值'] = outliersdata['车型代码'].map(building_max)\n",
    "    outliersdata['车型代码行驶时间标准差'] = outliersdata['车型代码'].map(building_std)\n",
    "    \n",
    "    df_group = data.groupby('车型代码')['通过车道的平均速度(km/h)']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['车型代码平均速度均值'] = data['车型代码'].map(building_mean)\n",
    "    data['车型代码平均速度中位数'] = data['车型代码'].map(building_median)\n",
    "    data['车型代码平均速度最小值'] = data['车型代码'].map(building_min)\n",
    "    data['车型代码平均速度最大值'] = data['车型代码'].map(building_max)\n",
    "    data['车型代码平均速度标准差'] = data['车型代码'].map(building_std)\n",
    "\n",
    "    outliersdata['车型代码平均速度均值'] = outliersdata['车型代码'].map(building_mean)\n",
    "    outliersdata['车型代码平均速度中位数'] = outliersdata['车型代码'].map(building_median)\n",
    "    outliersdata['车型代码平均速度最小值'] = outliersdata['车型代码'].map(building_min)\n",
    "    outliersdata['车型代码平均速度最大值'] = outliersdata['车型代码'].map(building_max)\n",
    "    outliersdata['车型代码平均速度标准差'] = outliersdata['车型代码'].map(building_std)\n",
    "    \n",
    "    df_group = data.groupby('出口站编号')['通过车道的平均速度(km/h)']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['出口站编号平均速度均值'] = data['出口站编号'].map(building_mean)\n",
    "    data['出口站编号平均速度中位数'] = data['出口站编号'].map(building_median)\n",
    "    data['出口站编号平均速度最小值'] = data['出口站编号'].map(building_min)\n",
    "    data['出口站编号平均速度最大值'] = data['出口站编号'].map(building_max)\n",
    "    data['出口站编号平均速度标准差'] = data['出口站编号'].map(building_std)\n",
    "\n",
    "    outliersdata['出口站编号平均速度均值'] = outliersdata['出口站编号'].map(building_mean)\n",
    "    outliersdata['出口站编号平均速度中位数'] = outliersdata['出口站编号'].map(building_median)\n",
    "    outliersdata['出口站编号平均速度最小值'] = outliersdata['出口站编号'].map(building_min)\n",
    "    outliersdata['出口站编号平均速度最大值'] = outliersdata['出口站编号'].map(building_max)\n",
    "    outliersdata['出口站编号平均速度标准差'] = outliersdata['出口站编号'].map(building_std)\n",
    "\n",
    "    df_group = data.groupby('入口站编号')['通过车道的平均速度(km/h)']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['入口站编号平均速度均值'] = data['入口站编号'].map(building_mean)\n",
    "    data['入口站编号平均速度中位数'] = data['入口站编号'].map(building_median)\n",
    "    data['入口站编号平均速度最小值'] = data['入口站编号'].map(building_min)\n",
    "    data['入口站编号平均速度最大值'] = data['入口站编号'].map(building_max)\n",
    "    data['入口站编号平均速度标准差'] = data['入口站编号'].map(building_std)\n",
    "\n",
    "    outliersdata['入口站编号平均速度均值'] = outliersdata['入口站编号'].map(building_mean)\n",
    "    outliersdata['入口站编号平均速度中位数'] = outliersdata['入口站编号'].map(building_median)\n",
    "    outliersdata['入口站编号平均速度最小值'] = outliersdata['入口站编号'].map(building_min)\n",
    "    outliersdata['入口站编号平均速度最大值'] = outliersdata['入口站编号'].map(building_max)\n",
    "    outliersdata['入口站编号平均速度标准差'] = outliersdata['入口站编号'].map(building_std)\n",
    "    \n",
    "    df_group = data.groupby('出口站编号')['行驶时间']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['出口站编号行驶时间均值'] = data['出口站编号'].map(building_mean)\n",
    "    data['出口站编号行驶时间中位数'] = data['出口站编号'].map(building_median)\n",
    "    data['出口站编号行驶时间最小值'] = data['出口站编号'].map(building_min)\n",
    "    data['出口站编号行驶时间最大值'] = data['出口站编号'].map(building_max)\n",
    "    data['出口站编号行驶时间标准差'] = data['出口站编号'].map(building_std)\n",
    "\n",
    "    outliersdata['出口站编号行驶时间均值'] = outliersdata['出口站编号'].map(building_mean)\n",
    "    outliersdata['出口站编号行驶时间中位数'] = outliersdata['出口站编号'].map(building_median)\n",
    "    outliersdata['出口站编号行驶时间最小值'] = outliersdata['出口站编号'].map(building_min)\n",
    "    outliersdata['出口站编号行驶时间最大值'] = outliersdata['出口站编号'].map(building_max)\n",
    "    outliersdata['出口站编号行驶时间标准差'] = outliersdata['出口站编号'].map(building_std)\n",
    "    \n",
    "    \n",
    "    df_group = data.groupby('入口站编号')['行驶时间']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['入口站编号行驶时间均值'] = data['入口站编号'].map(building_mean)\n",
    "    data['入口站编号行驶时间中位数'] = data['入口站编号'].map(building_median)\n",
    "    data['入口站编号行驶时间最小值'] = data['入口站编号'].map(building_min)\n",
    "    data['入口站编号行驶时间最大值'] = data['入口站编号'].map(building_max)\n",
    "    data['入口站编号行驶时间标准差'] = data['入口站编号'].map(building_std)\n",
    "\n",
    "    outliersdata['入口站编号行驶时间均值'] = outliersdata['入口站编号'].map(building_mean)\n",
    "    outliersdata['入口站编号行驶时间中位数'] = outliersdata['入口站编号'].map(building_median)\n",
    "    outliersdata['入口站编号行驶时间最小值'] = outliersdata['入口站编号'].map(building_min)\n",
    "    outliersdata['入口站编号行驶时间最大值'] = outliersdata['入口站编号'].map(building_max)\n",
    "    outliersdata['入口站编号行驶时间标准差'] = outliersdata['入口站编号'].map(building_std)\n",
    "    \n",
    "    \n",
    "    df_group = data.groupby('出口站编号')['超限率']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['出口站编号超限率均值'] = data['出口站编号'].map(building_mean)\n",
    "    data['出口站编号超限率中位数'] = data['出口站编号'].map(building_median)\n",
    "    data['出口站编号超限率最小值'] = data['出口站编号'].map(building_min)\n",
    "    data['出口站编号超限率最大值'] = data['出口站编号'].map(building_max)\n",
    "    data['出口站编号超限率标准差'] = data['出口站编号'].map(building_std)\n",
    "\n",
    "    outliersdata['出口站编号超限率均值'] = outliersdata['出口站编号'].map(building_mean)\n",
    "    outliersdata['出口站编号超限率中位数'] = outliersdata['出口站编号'].map(building_median)\n",
    "    outliersdata['出口站编号超限率最小值'] = outliersdata['出口站编号'].map(building_min)\n",
    "    outliersdata['出口站编号超限率最大值'] = outliersdata['出口站编号'].map(building_max)\n",
    "    outliersdata['出口站编号超限率标准差'] = outliersdata['出口站编号'].map(building_std)\n",
    "    \n",
    "    df_group = data.groupby('入口站编号')['超限率']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['入口站编号超限率均值'] = data['入口站编号'].map(building_mean)\n",
    "    data['入口站编号超限率中位数'] = data['入口站编号'].map(building_median)\n",
    "    data['入口站编号超限率最小值'] = data['入口站编号'].map(building_min)\n",
    "    data['入口站编号超限率最大值'] = data['入口站编号'].map(building_max)\n",
    "    data['入口站编号超限率标准差'] = data['入口站编号'].map(building_std)\n",
    "\n",
    "    outliersdata['入口站编号超限率均值'] = outliersdata['入口站编号'].map(building_mean)\n",
    "    outliersdata['入口站编号超限率中位数'] = outliersdata['入口站编号'].map(building_median)\n",
    "    outliersdata['入口站编号超限率最小值'] = outliersdata['入口站编号'].map(building_min)\n",
    "    outliersdata['入口站编号超限率最大值'] = outliersdata['入口站编号'].map(building_max)\n",
    "    outliersdata['入口站编号超限率标准差'] = outliersdata['入口站编号'].map(building_std)\n",
    "    \n",
    "    df_group = data.groupby('出口站编号')['车货总重']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['出口站编号车货总重均值'] = data['出口站编号'].map(building_mean)\n",
    "    data['出口站编号车货总重中位数'] = data['出口站编号'].map(building_median)\n",
    "    data['出口站编号车货总重最小值'] = data['出口站编号'].map(building_min)\n",
    "    data['出口站编号车货总重最大值'] = data['出口站编号'].map(building_max)\n",
    "    data['出口站编号车货总重标准差'] = data['出口站编号'].map(building_std)\n",
    "\n",
    "    outliersdata['出口站编号车货总重均值'] = outliersdata['出口站编号'].map(building_mean)\n",
    "    outliersdata['出口站编号车货总重中位数'] = outliersdata['出口站编号'].map(building_median)\n",
    "    outliersdata['出口站编号车货总重最小值'] = outliersdata['出口站编号'].map(building_min)\n",
    "    outliersdata['出口站编号车货总重最大值'] = outliersdata['出口站编号'].map(building_max)\n",
    "    outliersdata['出口站编号车货总重标准差'] = outliersdata['出口站编号'].map(building_std)\n",
    "    \n",
    "    df_group = data.groupby('入口站编号')['车货总重']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['入口站编号车货总重均值'] = data['入口站编号'].map(building_mean)\n",
    "    data['入口站编号车货总重中位数'] = data['入口站编号'].map(building_median)\n",
    "    data['入口站编号车货总重最小值'] = data['入口站编号'].map(building_min)\n",
    "    data['入口站编号车货总重最大值'] = data['入口站编号'].map(building_max)\n",
    "    data['入口站编号车货总重标准差'] = data['入口站编号'].map(building_std)\n",
    "\n",
    "    outliersdata['入口站编号车货总重均值'] = outliersdata['入口站编号'].map(building_mean)\n",
    "    outliersdata['入口站编号车货总重中位数'] = outliersdata['入口站编号'].map(building_median)\n",
    "    outliersdata['入口站编号车货总重最小值'] = outliersdata['入口站编号'].map(building_min)\n",
    "    outliersdata['入口站编号车货总重最大值'] = outliersdata['入口站编号'].map(building_max)\n",
    "    outliersdata['入口站编号车货总重标准差'] = outliersdata['入口站编号'].map(building_std)\n",
    "    \n",
    "    df_group = data.groupby('车型代码')['车货总重']\n",
    "\n",
    "    building_mean = df_group.mean().astype(np.float16)\n",
    "    building_median = df_group.median().astype(np.float16)\n",
    "    building_min = df_group.min().astype(np.float16)\n",
    "    building_max = df_group.max().astype(np.float16)\n",
    "    building_std = df_group.std().astype(np.float16)\n",
    "\n",
    "    data['车型代码车货总重均值'] = data['车型代码'].map(building_mean)\n",
    "    data['车型代码车货总重中位数'] = data['车型代码'].map(building_median)\n",
    "    data['车型代码车货总重最小值'] = data['车型代码'].map(building_min)\n",
    "    data['车型代码车货总重最大值'] = data['车型代码'].map(building_max)\n",
    "    data['车型代码车货总重标准差'] = data['车型代码'].map(building_std)\n",
    "\n",
    "    outliersdata['车型代码车货总重均值'] = outliersdata['车型代码'].map(building_mean)\n",
    "    outliersdata['车型代码车货总重中位数'] = outliersdata['车型代码'].map(building_median)\n",
    "    outliersdata['车型代码车货总重最小值'] = outliersdata['车型代码'].map(building_min)\n",
    "    outliersdata['车型代码车货总重最大值'] = outliersdata['车型代码'].map(building_max)\n",
    "    outliersdata['车型代码车货总重标准差'] = outliersdata['车型代码'].map(building_std)\n",
    "    \n",
    "    data['入口站编号平均速度离差'] = data['通过车道的平均速度(km/h)'] - data['入口站编号平均速度中位数']\n",
    "    data['出口站编号平均速度离差'] = data['通过车道的平均速度(km/h)'] - data['出口站编号平均速度中位数']\n",
    "    data['入口站编号行驶时间离差'] = data['行驶时间'] - data['入口站编号行驶时间中位数']\n",
    "    data['出口站编号行驶时间离差'] = data['行驶时间'] - data['出口站编号行驶时间中位数']\n",
    "\n",
    "    data['入口站编号平均速度离差'] = data['入口站编号平均速度离差'].apply(np.exp)\n",
    "    data['出口站编号平均速度离差'] = data['出口站编号平均速度离差'].apply(np.exp)\n",
    "    data['入口站编号行驶时间离差'] = data['入口站编号行驶时间离差'].apply(np.log)\n",
    "    data['出口站编号行驶时间离差'] = data['出口站编号行驶时间离差'].apply(np.log)\n",
    "\n",
    "    data['入口站编号超限率离差'] = data['超限率'] - data['入口站编号超限率中位数']\n",
    "    data['出口站编号超限率离差'] = data['超限率'] - data['出口站编号超限率中位数']\n",
    "    data['入口站编号车货总重离差'] = data['车货总重'] - data['入口站编号车货总重中位数']\n",
    "    data['出口站编号车货总重离差'] = data['车货总重'] - data['出口站编号车货总重中位数']\n",
    "\n",
    "    data['入口站编号超限率离差'] = np.abs(data['入口站编号超限率离差']).apply(np.log)\n",
    "    data['出口站编号超限率离差'] = np.abs(data['出口站编号超限率离差']).apply(np.log)\n",
    "    data['入口站编号车货总重离差'] = np.abs(data['入口站编号车货总重离差']).apply(np.log)\n",
    "    data['出口站编号车货总重离差'] = np.abs(data['出口站编号车货总重离差']).apply(np.log)\n",
    "\n",
    "    data['车型代码平均速度离差'] = data['通过车道的平均速度(km/h)'] - data['车型代码平均速度中位数']\n",
    "    data['车型代码行驶时间离差'] = data['行驶时间'] - data['车型代码行驶时间中位数']\n",
    "    data['车型代码超限率离差'] = data['超限率'] - data['车型代码超限率中位数']\n",
    "    data['车型代码车货总重离差'] = data['车货总重'] - data['车型代码车货总重中位数']\n",
    "\n",
    "    data['车型代码平均速度离差'] = data['车型代码平均速度离差'].apply(np.exp)\n",
    "    data['车型代码行驶时间离差'] = data['车型代码行驶时间离差'].apply(np.log)\n",
    "    data['车型代码超限率离差'] = np.abs(data['车型代码超限率离差']).apply(np.log)\n",
    "    data['车型代码车货总重离差'] = np.abs(data['车型代码车货总重离差']).apply(np.log)\n",
    "\n",
    "    #=====================outliers\n",
    "\n",
    "    outliersdata['入口站编号平均速度离差'] = outliersdata['通过车道的平均速度(km/h)'] - outliersdata['入口站编号平均速度中位数']\n",
    "    outliersdata['出口站编号平均速度离差'] = outliersdata['通过车道的平均速度(km/h)'] - outliersdata['出口站编号平均速度中位数']\n",
    "    outliersdata['入口站编号行驶时间离差'] = outliersdata['行驶时间'] - outliersdata['入口站编号行驶时间中位数']\n",
    "    outliersdata['出口站编号行驶时间离差'] = outliersdata['行驶时间'] - outliersdata['出口站编号行驶时间中位数']\n",
    "\n",
    "    outliersdata['入口站编号平均速度离差'] = outliersdata['入口站编号平均速度离差'].apply(np.exp)\n",
    "    outliersdata['出口站编号平均速度离差'] = outliersdata['出口站编号平均速度离差'].apply(np.exp)\n",
    "    outliersdata['入口站编号行驶时间离差'] = outliersdata['入口站编号行驶时间离差'].apply(np.log)\n",
    "    outliersdata['出口站编号行驶时间离差'] = outliersdata['出口站编号行驶时间离差'].apply(np.log)\n",
    "\n",
    "    outliersdata['入口站编号超限率离差'] = outliersdata['超限率'] - outliersdata['入口站编号超限率中位数']\n",
    "    outliersdata['出口站编号超限率离差'] = outliersdata['超限率'] - outliersdata['出口站编号超限率中位数']\n",
    "    outliersdata['入口站编号车货总重离差'] = outliersdata['车货总重'] - outliersdata['入口站编号车货总重中位数']\n",
    "    outliersdata['出口站编号车货总重离差'] = outliersdata['车货总重'] - outliersdata['出口站编号车货总重中位数']\n",
    "\n",
    "    outliersdata['入口站编号超限率离差'] = np.abs(outliersdata['入口站编号超限率离差']).apply(np.log)\n",
    "    outliersdata['出口站编号超限率离差'] = np.abs(outliersdata['出口站编号超限率离差']).apply(np.log)\n",
    "    outliersdata['入口站编号车货总重离差'] = np.abs(outliersdata['入口站编号车货总重离差']).apply(np.log)\n",
    "    outliersdata['出口站编号车货总重离差'] = np.abs(outliersdata['出口站编号车货总重离差']).apply(np.log)\n",
    "\n",
    "    outliersdata['车型代码平均速度离差'] = outliersdata['通过车道的平均速度(km/h)'] - outliersdata['车型代码平均速度中位数']\n",
    "    outliersdata['车型代码行驶时间离差'] = outliersdata['行驶时间'] - outliersdata['车型代码行驶时间中位数']\n",
    "    outliersdata['车型代码超限率离差'] = outliersdata['超限率'] - outliersdata['车型代码超限率中位数']\n",
    "    outliersdata['车型代码车货总重离差'] = outliersdata['车货总重'] - outliersdata['车型代码车货总重中位数']\n",
    "\n",
    "    outliersdata['车型代码平均速度离差'] = outliersdata['车型代码平均速度离差'].apply(np.exp)\n",
    "    outliersdata['车型代码行驶时间离差'] = outliersdata['车型代码行驶时间离差'].apply(np.log)\n",
    "    outliersdata['车型代码超限率离差'] = np.abs(outliersdata['车型代码超限率离差']).apply(np.log)\n",
    "    outliersdata['车型代码车货总重离差'] = np.abs(outliersdata['车型代码车货总重离差']).apply(np.log)\n",
    "    \n",
    "    data = data.replace([np.inf, -np.inf], np.nan)\n",
    "    outliersdata = outliersdata.replace([np.inf, -np.inf], np.nan)\n",
    "    data = data.fillna(-1)\n",
    "    outliersdata = outliersdata.fillna(-1)\n",
    "\n",
    "    data.to_pickle('cleandata/' + dataname + 'feg.pkl')\n",
    "    outliersdata.to_pickle('outliers/' + dataname + 'feg.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = False\n",
    "if save:\n",
    "    file = ['July.csv','Aug.csv','Sep.csv','Oct.csv', 'Nov.csv','Dec.csv']\n",
    "\n",
    "    for f in file:\n",
    "        data = pd.read_csv('cleandata/' + f)\n",
    "        outliersdata = pd.read_csv('outliers/' + f)\n",
    "        pipeline_feature(data, outliersdata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "droptime = ['入口日期及时间','出口日期及时间']\n",
    "cat_feature = ['入口站编号', '出口站编号', '车型代码', '轴型及轴重', 'entryweek', 'entryday', 'entryhour', 'exitweek', 'exitday', 'exithour']\n",
    "time_feature = ['entryweek', 'entryday', 'entryhour', 'exitweek', 'exitday', 'exithour']\n",
    "base_feature = ['里程', '总轴数', '车货总重', '限重', '超限率', '是否ETC车道代码', '行驶时间', '通过车道的平均速度(km/h)']\n",
    "target = '是否绿色通道车辆代码'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1040/1040 [==============================] - 1s 1ms/step\n",
      "0.986825041817806\n",
      "auc score: 0.9604952640025719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    528065\n",
      "           1       0.10      0.09      0.09      4005\n",
      "\n",
      "    accuracy                           0.99    532070\n",
      "   macro avg       0.54      0.54      0.54    532070\n",
      "weighted avg       0.99      0.99      0.99    532070\n",
      "\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "outliers acc: 0.7877465857359636\n",
      "97/97 [==============================] - 0s 1ms/step\n",
      "0.897312782440284\n",
      "auc score: 0.6766734659194991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95     44299\n",
      "           1       0.58      0.13      0.21      5269\n",
      "\n",
      "    accuracy                           0.90     49568\n",
      "   macro avg       0.74      0.56      0.58     49568\n",
      "weighted avg       0.87      0.90      0.87     49568\n",
      "\n",
      "8/8 [==============================] - 0s 3ms/step\n",
      "outliers acc: 0.000249500998003992\n",
      "1040/1040 [==============================] - 1s 1ms/step\n",
      "0.9868232366611348\n",
      "auc score: 0.9604902544093151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    528068\n",
      "           1       0.10      0.09      0.09      4005\n",
      "\n",
      "    accuracy                           0.99    532073\n",
      "   macro avg       0.54      0.54      0.54    532073\n",
      "weighted avg       0.99      0.99      0.99    532073\n",
      "\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "outliers acc: 0.7877465857359636\n",
      "1040/1040 [==============================] - 1s 1ms/step\n",
      "0.9867622102824024\n",
      "auc score: 0.9604812713879765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    528105\n",
      "           1       0.10      0.09      0.09      4008\n",
      "\n",
      "    accuracy                           0.99    532113\n",
      "   macro avg       0.54      0.54      0.54    532113\n",
      "weighted avg       0.99      0.99      0.99    532113\n",
      "\n",
      "11/11 [==============================] - 0s 3ms/step\n",
      "outliers acc: 0.7849686847599165\n",
      "97/97 [==============================] - 0s 1ms/step\n",
      "0.8972745062438218\n",
      "auc score: 0.6766150451103113\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.95     44300\n",
      "           1       0.58      0.13      0.21      5269\n",
      "\n",
      "    accuracy                           0.90     49569\n",
      "   macro avg       0.74      0.56      0.58     49569\n",
      "weighted avg       0.87      0.90      0.87     49569\n",
      "\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "outliers acc: 0.000249500998003992\n",
      "1040/1040 [==============================] - 1s 1ms/step\n",
      "0.9868232366611348\n",
      "auc score: 0.9604902544093151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    528068\n",
      "           1       0.10      0.09      0.09      4005\n",
      "\n",
      "    accuracy                           0.99    532073\n",
      "   macro avg       0.54      0.54      0.54    532073\n",
      "weighted avg       0.99      0.99      0.99    532073\n",
      "\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "outliers acc: 0.7877465857359636\n"
     ]
    }
   ],
   "source": [
    "file = ['July.csvfeg.pkl','Aug.csvfeg.pkl','Sep.csvfeg.pkl','Oct.csvfeg.pkl', 'Nov.csvfeg.pkl','Dec.csvfeg.pkl']\n",
    "batch_size = 512\n",
    "for f in file:\n",
    "    data = pd.read_pickle('cleandata/' + f)\n",
    "    data.drop(droptime, axis=1, inplace=True)\n",
    "    real_feature = [i for i in data.columns if i not in cat_feature and i != target and i not in base_feature]\n",
    "    \n",
    "    X = data[base_feature + cat_feature + real_feature]\n",
    "    y = data[target]\n",
    "    \n",
    "    trn_cat = X[cat_feature]\n",
    "    trn_real = X[base_feature + real_feature]\n",
    "    \n",
    "    sds_real = joblib.load('models/sds_real')\n",
    "    trn_real = sds_real.transform(trn_real)\n",
    "    \n",
    "    model = tf.keras.models.load_model('models/conv1d_upsampling.h5')\n",
    "    \n",
    "    pred = model.predict([trn_real, trn_cat.values], batch_size=batch_size, verbose=1)\n",
    "    print(accuracy_score(y, np.round(pred)))\n",
    "    print(\"auc score:\", roc_auc_score(y,pred))\n",
    "    print(classification_report(y, np.round(pred)))\n",
    "    \n",
    "    outliers = pd.read_pickle('outliers/' + f)\n",
    "    outliers.drop(droptime, axis=1, inplace=True)\n",
    "\n",
    "    outliersX = outliers[base_feature + cat_feature + real_feature]\n",
    "    outliersy = outliers[target]\n",
    "\n",
    "    outlierstst_cat = outliersX[cat_feature]\n",
    "\n",
    "    outlierstst_real = outliersX[base_feature + real_feature]\n",
    "    outlierstst_real = sds_real.transform(outlierstst_real)\n",
    "    \n",
    "    outliersypred = model.predict([outlierstst_real, outlierstst_cat.values], batch_size=batch_size, verbose=1)\n",
    "    print(\"outliers acc: {}\".format(accuracy_score(outliersy, np.round(outliersypred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "728/728 [==============================] - 1s 1ms/step\n",
      "acc: 0.9868062472982878\n",
      "auc score: 0.9601777441279159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    369665\n",
      "           1       0.10      0.09      0.09      2784\n",
      "\n",
      "    accuracy                           0.99    372449\n",
      "   macro avg       0.55      0.54      0.54    372449\n",
      "weighted avg       0.99      0.99      0.99    372449\n",
      "\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "outliers acc: 0.7877465857359636\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "acc: 0.8982362095798029\n",
      "auc score: 0.6783144861060064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     31039\n",
      "           1       0.58      0.13      0.21      3659\n",
      "\n",
      "    accuracy                           0.90     34698\n",
      "   macro avg       0.74      0.56      0.58     34698\n",
      "weighted avg       0.87      0.90      0.87     34698\n",
      "\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "outliers acc: 0.000249500998003992\n",
      "728/728 [==============================] - 1s 1ms/step\n",
      "acc: 0.986830517757993\n",
      "auc score: 0.9605693059690739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    369692\n",
      "           1       0.10      0.09      0.10      2760\n",
      "\n",
      "    accuracy                           0.99    372452\n",
      "   macro avg       0.55      0.54      0.54    372452\n",
      "weighted avg       0.99      0.99      0.99    372452\n",
      "\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "outliers acc: 0.7877465857359636\n",
      "728/728 [==============================] - 1s 1ms/step\n",
      "acc: 0.9867778135738832\n",
      "auc score: 0.9603918433117701\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    369693\n",
      "           1       0.09      0.09      0.09      2787\n",
      "\n",
      "    accuracy                           0.99    372480\n",
      "   macro avg       0.54      0.54      0.54    372480\n",
      "weighted avg       0.99      0.99      0.99    372480\n",
      "\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "outliers acc: 0.7849686847599165\n",
      "68/68 [==============================] - 0s 1ms/step\n",
      "acc: 0.8982679616127266\n",
      "auc score: 0.6777352345279103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95     31041\n",
      "           1       0.58      0.13      0.21      3658\n",
      "\n",
      "    accuracy                           0.90     34699\n",
      "   macro avg       0.74      0.56      0.58     34699\n",
      "weighted avg       0.87      0.90      0.87     34699\n",
      "\n",
      "8/8 [==============================] - 0s 1ms/step\n",
      "outliers acc: 0.000249500998003992\n",
      "728/728 [==============================] - 1s 1ms/step\n",
      "acc: 0.986830517757993\n",
      "auc score: 0.9605693059690739\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99    369692\n",
      "           1       0.10      0.09      0.10      2760\n",
      "\n",
      "    accuracy                           0.99    372452\n",
      "   macro avg       0.55      0.54      0.54    372452\n",
      "weighted avg       0.99      0.99      0.99    372452\n",
      "\n",
      "11/11 [==============================] - 0s 1ms/step\n",
      "outliers acc: 0.7877465857359636\n"
     ]
    }
   ],
   "source": [
    "file = ['July.csvfeg.pkl','Aug.csvfeg.pkl','Sep.csvfeg.pkl','Oct.csvfeg.pkl', 'Nov.csvfeg.pkl','Dec.csvfeg.pkl']\n",
    "batch_size = 512\n",
    "\n",
    "Callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=3),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\n",
    "]\n",
    "\n",
    "for f in file:\n",
    "    data = pd.read_pickle('cleandata/' + f)\n",
    "    data.drop(droptime, axis=1, inplace=True)\n",
    "    real_feature = [i for i in data.columns if i not in cat_feature and i != target and i not in base_feature]\n",
    "    \n",
    "    X = data[base_feature + cat_feature + real_feature]\n",
    "    y = data[target]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=2020)\n",
    "    \n",
    "    trn_cat = X_train[cat_feature]\n",
    "    trn_real = X_train[base_feature + real_feature]\n",
    "    \n",
    "    tst_cat = X_test[cat_feature]\n",
    "    tst_real = X_test[base_feature + real_feature]\n",
    "\n",
    "    sds_real = joblib.load('models/sds_real')\n",
    "    trn_real = sds_real.transform(trn_real)\n",
    "    tst_real = sds_real.transform(tst_real)\n",
    "    \n",
    "    batch_size = 512\n",
    "    model.fit([trn_real, trn_cat.values], y_train, batch_size=batch_size, verbose=0, epochs=20, validation_split=0.2, callbacks=Callbacks)\n",
    "\n",
    "    model = tf.keras.models.load_model('models/conv1d_upsampling.h5')\n",
    "    \n",
    "    pred = model.predict([tst_real, tst_cat.values], batch_size=batch_size, verbose=1)\n",
    "    print(\"acc: {}\".format(accuracy_score(y_test, np.round(pred))))\n",
    "    print(\"auc score:\", roc_auc_score(y_test,pred))\n",
    "    print(classification_report(y_test, np.round(pred)))\n",
    "    \n",
    "    outliers = pd.read_pickle('outliers/' + f)\n",
    "    outliers.drop(droptime, axis=1, inplace=True)\n",
    "\n",
    "    outliersX = outliers[base_feature + cat_feature + real_feature]\n",
    "    outliersy = outliers[target]\n",
    "    outlierstst_cat = outliersX[cat_feature]\n",
    "    outlierstst_real = outliersX[base_feature + real_feature]\n",
    "    outlierstst_real = sds_real.transform(outlierstst_real)\n",
    "    \n",
    "    outliersypred = model.predict([outlierstst_real, outlierstst_cat.values], batch_size=batch_size, verbose=1)\n",
    "    print(\"outliers acc: {}\".format(accuracy_score(outliersy, np.round(outliersypred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
